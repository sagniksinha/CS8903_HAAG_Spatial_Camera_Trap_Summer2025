{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a2e025d-4a9b-49e6-b6ef-249fcda93c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6d2329-13d0-4335-8709-0dccc2001e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "1    9508\n",
      "2      46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "deployments_csv = r\"C:\\Users\\sagni\\Documents\\Personal Files\\Research\\doi_10_5061_dryad_k0p2ngfhn__v20250410\\ssusa_finaldeployments.csv\"\n",
    "clustered_excel = r\"C:\\Users\\sagni\\Documents\\Personal Files\\Research\\doi_10_5061_dryad_k0p2ngfhn__v20250410\\Clustered_Data_Updated.xlsx\"\n",
    "\n",
    "# Load data\n",
    "df_deployments = pd.read_csv(deployments_csv)\n",
    "df_clustered = pd.read_excel(clustered_excel)\n",
    "\n",
    "# Extract Deployment_IDs from Excel (assuming column name is 'Deployment_ID')\n",
    "deployment_ids_in_excel = df_clustered['Deployment_ID'].unique()\n",
    "\n",
    "# Filter deployments to only those Deployment_IDs present in Excel\n",
    "filtered_deployments = df_deployments[df_deployments['Deployment_ID'].isin(deployment_ids_in_excel)]\n",
    "\n",
    "# Count distinct years per Deployment_ID\n",
    "distinct_years_count = filtered_deployments.groupby('Deployment_ID')['Year'].nunique()\n",
    "\n",
    "# Count how many Deployment_IDs have each distinct year count\n",
    "count_distribution = distinct_years_count.value_counts().sort_index()\n",
    "\n",
    "print(count_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc64387-8b5e-449c-b138-cc5d45891fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "1    86\n",
      "2    30\n",
      "3    17\n",
      "4    22\n",
      "5    43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select only Deployment_ID and Cluster_Agglo_Updated columns from clustered data\n",
    "df_clustered_subset = df_clustered[['Deployment_ID', 'Cluster_Agglo_Updated']]\n",
    "\n",
    "# Merge on Deployment_ID (inner join to keep only matching Deployment_IDs)\n",
    "df_merged = df_deployments.merge(df_clustered_subset, on='Deployment_ID', how='inner')\n",
    "\n",
    "# Count distinct years per cluster\n",
    "distinct_years_per_cluster = df_merged.groupby('Cluster_Agglo_Updated')['Year'].nunique()\n",
    "\n",
    "# Count distribution of how many clusters have a given number of distinct years\n",
    "count_distribution = distinct_years_per_cluster.value_counts().sort_index()\n",
    "\n",
    "print(count_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d3a573-3b17-4176-9dd8-b666837d9b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_years_count\n",
      "1    1295\n",
      "2     954\n",
      "3    1074\n",
      "4    1459\n",
      "5    4818\n",
      "Name: record_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Count records and unique years per Deployment_ID\n",
    "deployment_stats = (\n",
    "    df_merged.groupby('Cluster_Agglo_Updated')\n",
    "    .agg(record_count=('Year', 'count'), unique_years_count=('Year', 'nunique'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 2: Group by unique_years_count and sum the record_count\n",
    "summary = (\n",
    "    deployment_stats\n",
    "    .groupby('unique_years_count')['record_count']\n",
    "    .sum()\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd8285bb-12e4-4e9a-b11f-a78ae3c19908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Temp\\ipykernel_28132\\3411936815.py:16: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_snapshot = pd.read_csv( r\"C:\\Users\\sagni\\Documents\\Personal Files\\Research\\doi_10_5061_dryad_k0p2ngfhn__v20250410\\merged_snapshot_usa_with_label.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of deployments with 5 unique years - before filtering : 9554\n",
      "Number of records in merged snapshot for these deployments  - before filtering : 885087\n",
      "\n",
      "Number of deployments with 5 unique years: 4799\n",
      "Number of records in merged snapshot for these deployments: 478810\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Step 3: Filter clusters where unique_year_count == 5\n",
    "# ---------------------------------------------\n",
    "clusters_with_5_years = deployment_stats[deployment_stats['unique_years_count'] >= 5]['Cluster_Agglo_Updated']\n",
    "\n",
    "# Filter the deployment-level merged data for those clusters\n",
    "filtered_deployments = df_merged[df_merged['Cluster_Agglo_Updated'].isin(clusters_with_5_years)]\n",
    "\n",
    "# Get the Deployment_IDs from these filtered deployments\n",
    "deployment_ids_with_5_years = filtered_deployments['Deployment_ID'].unique()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 4: Load snapshot data and filter\n",
    "# ---------------------------------------------\n",
    "# Read the merged snapshot dataset\n",
    "df_snapshot = pd.read_csv( r\"C:\\Users\\sagni\\Documents\\Personal Files\\Research\\doi_10_5061_dryad_k0p2ngfhn__v20250410\\merged_snapshot_usa_with_label.csv\")\n",
    "\n",
    "# Filter it to only include Deployment_IDs with 5-year clusters\n",
    "filtered_snapshot = df_snapshot[df_snapshot['Deployment_ID'].isin(deployment_ids_with_5_years)]\n",
    "deployment_ids_with_5_years2 = df_snapshot['Deployment_ID'].unique()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 5: Report number of matched records\n",
    "# ---------------------------------------------\n",
    "print(f\"\\nNumber of deployments with 5 unique years - before filtering : {len(deployment_ids_with_5_years2)}\")\n",
    "print(f\"Number of records in merged snapshot for these deployments  - before filtering : {len(df_snapshot)}\")\n",
    "print(f\"\\nNumber of deployments with 5 unique years: {len(deployment_ids_with_5_years)}\")\n",
    "print(f\"Number of records in merged snapshot for these deployments: {len(filtered_snapshot)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd93e374-abf3-4c34-9b4f-f19c67bf0bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in final: 478810\n"
     ]
    }
   ],
   "source": [
    "# Select only Deployment_ID and Cluster_Agglo_Updated columns from clustered data\n",
    "df_clustered_subset = df_clustered[['Deployment_ID', 'Cluster_Agglo_Updated']]\n",
    "df_clustered_subset = df_clustered_subset[df_clustered_subset['Cluster_Agglo_Updated'].isin(clusters_with_5_years)]\n",
    "\n",
    "# Merge on Deployment_ID (inner join to keep only matching Deployment_IDs)\n",
    "final = df_snapshot.merge(df_clustered_subset, on='Deployment_ID', how='inner')\n",
    "print(f\"Number of records in final: {len(final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e47726d7-a40b-4c14-9317-ca4f4f73a771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Project</th>\n",
       "      <th>Camera_Trap_Array</th>\n",
       "      <th>Deployment_ID</th>\n",
       "      <th>Sequence_ID</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Class</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>...</th>\n",
       "      <th>Survey_Nights</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Habitat</th>\n",
       "      <th>Development_Level</th>\n",
       "      <th>Feature_Type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>Cluster_Agglo_Updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>Snapshot USA 2019</td>\n",
       "      <td>Crupi</td>\n",
       "      <td>AK_Forest_Chilkat_Preserve_1</td>\n",
       "      <td>d58722s1</td>\n",
       "      <td>2019/08/31 06:50:00</td>\n",
       "      <td>2019/08/31 06:50:00</td>\n",
       "      <td>mammalia</td>\n",
       "      <td>carnivora</td>\n",
       "      <td>ursidae</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>59.42643</td>\n",
       "      <td>-136.2225</td>\n",
       "      <td>forest</td>\n",
       "      <td>wild</td>\n",
       "      <td>water source</td>\n",
       "      <td>-1.097526e+06</td>\n",
       "      <td>1.305164e+07</td>\n",
       "      <td>16</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>Snapshot USA 2019</td>\n",
       "      <td>Crupi</td>\n",
       "      <td>AK_Forest_Chilkat_Preserve_1</td>\n",
       "      <td>d58722s2</td>\n",
       "      <td>2019/08/31 14:15:00</td>\n",
       "      <td>2019/08/31 14:17:00</td>\n",
       "      <td>mammalia</td>\n",
       "      <td>carnivora</td>\n",
       "      <td>ursidae</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>59.42643</td>\n",
       "      <td>-136.2225</td>\n",
       "      <td>forest</td>\n",
       "      <td>wild</td>\n",
       "      <td>water source</td>\n",
       "      <td>-1.097526e+06</td>\n",
       "      <td>1.305164e+07</td>\n",
       "      <td>16</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>Snapshot USA 2019</td>\n",
       "      <td>Crupi</td>\n",
       "      <td>AK_Forest_Chilkat_Preserve_1</td>\n",
       "      <td>d58722s3</td>\n",
       "      <td>2019/08/31 18:22:00</td>\n",
       "      <td>2019/08/31 18:22:00</td>\n",
       "      <td>mammalia</td>\n",
       "      <td>carnivora</td>\n",
       "      <td>ursidae</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>59.42643</td>\n",
       "      <td>-136.2225</td>\n",
       "      <td>forest</td>\n",
       "      <td>wild</td>\n",
       "      <td>water source</td>\n",
       "      <td>-1.097526e+06</td>\n",
       "      <td>1.305164e+07</td>\n",
       "      <td>16</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Snapshot USA 2019</td>\n",
       "      <td>Crupi</td>\n",
       "      <td>AK_Forest_Chilkat_Preserve_1</td>\n",
       "      <td>d58722s4</td>\n",
       "      <td>2019/08/31 20:58:00</td>\n",
       "      <td>2019/08/31 20:58:00</td>\n",
       "      <td>mammalia</td>\n",
       "      <td>carnivora</td>\n",
       "      <td>ursidae</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>59.42643</td>\n",
       "      <td>-136.2225</td>\n",
       "      <td>forest</td>\n",
       "      <td>wild</td>\n",
       "      <td>water source</td>\n",
       "      <td>-1.097526e+06</td>\n",
       "      <td>1.305164e+07</td>\n",
       "      <td>16</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Snapshot USA 2019</td>\n",
       "      <td>Crupi</td>\n",
       "      <td>AK_Forest_Chilkat_Preserve_1</td>\n",
       "      <td>d58722s4</td>\n",
       "      <td>2019/08/31 20:58:00</td>\n",
       "      <td>2019/08/31 20:58:00</td>\n",
       "      <td>mammalia</td>\n",
       "      <td>carnivora</td>\n",
       "      <td>ursidae</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>59.42643</td>\n",
       "      <td>-136.2225</td>\n",
       "      <td>forest</td>\n",
       "      <td>wild</td>\n",
       "      <td>water source</td>\n",
       "      <td>-1.097526e+06</td>\n",
       "      <td>1.305164e+07</td>\n",
       "      <td>16</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year            Project Camera_Trap_Array                 Deployment_ID  \\\n",
       "0  2019  Snapshot USA 2019             Crupi  AK_Forest_Chilkat_Preserve_1   \n",
       "1  2019  Snapshot USA 2019             Crupi  AK_Forest_Chilkat_Preserve_1   \n",
       "2  2019  Snapshot USA 2019             Crupi  AK_Forest_Chilkat_Preserve_1   \n",
       "3  2019  Snapshot USA 2019             Crupi  AK_Forest_Chilkat_Preserve_1   \n",
       "4  2019  Snapshot USA 2019             Crupi  AK_Forest_Chilkat_Preserve_1   \n",
       "\n",
       "  Sequence_ID           Start_Time             End_Time     Class      Order  \\\n",
       "0    d58722s1  2019/08/31 06:50:00  2019/08/31 06:50:00  mammalia  carnivora   \n",
       "1    d58722s2  2019/08/31 14:15:00  2019/08/31 14:17:00  mammalia  carnivora   \n",
       "2    d58722s3  2019/08/31 18:22:00  2019/08/31 18:22:00  mammalia  carnivora   \n",
       "3    d58722s4  2019/08/31 20:58:00  2019/08/31 20:58:00  mammalia  carnivora   \n",
       "4    d58722s4  2019/08/31 20:58:00  2019/08/31 20:58:00  mammalia  carnivora   \n",
       "\n",
       "    Family  ... Survey_Nights  Latitude Longitude Habitat Development_Level  \\\n",
       "0  ursidae  ...            64  59.42643 -136.2225  forest              wild   \n",
       "1  ursidae  ...            64  59.42643 -136.2225  forest              wild   \n",
       "2  ursidae  ...            64  59.42643 -136.2225  forest              wild   \n",
       "3  ursidae  ...            64  59.42643 -136.2225  forest              wild   \n",
       "4  ursidae  ...            64  59.42643 -136.2225  forest              wild   \n",
       "\n",
       "   Feature_Type             x             y cluster_label  \\\n",
       "0  water source -1.097526e+06  1.305164e+07            16   \n",
       "1  water source -1.097526e+06  1.305164e+07            16   \n",
       "2  water source -1.097526e+06  1.305164e+07            16   \n",
       "3  water source -1.097526e+06  1.305164e+07            16   \n",
       "4  water source -1.097526e+06  1.305164e+07            16   \n",
       "\n",
       "   Cluster_Agglo_Updated  \n",
       "0                    156  \n",
       "1                    156  \n",
       "2                    156  \n",
       "3                    156  \n",
       "4                    156  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46dac960-fec7-45d2-8638-8e821fe33e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter and dedupe\n",
    "df = final[['Year', 'Species', 'Cluster_Agglo_Updated']].drop_duplicates()\n",
    "\n",
    "# Ensure Year is sorted as int\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "years = sorted(df['Year'].unique())  # [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "# ------------------ Species Movement: Jaccard of Clusters ------------------\n",
    "\n",
    "species_year_clusters = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "# Build mapping: Species → Year → Set of Clusters\n",
    "for _, row in df.iterrows():\n",
    "    species_year_clusters[row['Species']][row['Year']].add(row['Cluster_Agglo_Updated'])\n",
    "\n",
    "species_jaccard_scores = []\n",
    "\n",
    "for species, year_map in species_year_clusters.items():\n",
    "    for y1, y2 in zip(years, years[1:]):  # consecutive year pairs\n",
    "        set1 = year_map.get(y1, set())\n",
    "        set2 = year_map.get(y2, set())\n",
    "        if set1 or set2:\n",
    "            intersection = len(set1 & set2)\n",
    "            union = len(set1 | set2)\n",
    "            jaccard = intersection / union if union != 0 else None\n",
    "            species_jaccard_scores.append({\n",
    "                'Species': species,\n",
    "                'Year1': y1,\n",
    "                'Year2': y2,\n",
    "                'JaccardSimilarity': jaccard\n",
    "            })\n",
    "\n",
    "df_species_movement = pd.DataFrame(species_jaccard_scores)\n",
    "\n",
    "# ------------------ Location Movement: Jaccard of Species ------------------\n",
    "\n",
    "cluster_year_species = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "# Build mapping: Cluster → Year → Set of Species\n",
    "for _, row in df.iterrows():\n",
    "    cluster_year_species[row['Cluster_Agglo_Updated']][row['Year']].add(row['Species'])\n",
    "\n",
    "cluster_jaccard_scores = []\n",
    "\n",
    "for cluster, year_map in cluster_year_species.items():\n",
    "    for y1, y2 in zip(years, years[1:]):  # consecutive year pairs\n",
    "        set1 = year_map.get(y1, set())\n",
    "        set2 = year_map.get(y2, set())\n",
    "        if set1 or set2:\n",
    "            intersection = len(set1 & set2)\n",
    "            union = len(set1 | set2)\n",
    "            jaccard = intersection / union if union != 0 else None\n",
    "            cluster_jaccard_scores.append({\n",
    "                'Cluster_Agglo_Updated': cluster,\n",
    "                'Year1': y1,\n",
    "                'Year2': y2,\n",
    "                'JaccardSimilarity': jaccard\n",
    "            })\n",
    "\n",
    "df_cluster_movement = pd.DataFrame(cluster_jaccard_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "020e2898-42e9-4933-9c62-a75580185c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species\n",
       "cryptoleucus    0.0\n",
       "fuscipes        0.0\n",
       "fuscescens      0.0\n",
       "fuliginosus     0.0\n",
       "formicivorus    0.0\n",
       "               ... \n",
       "arctos          1.0\n",
       "rufa            1.0\n",
       "bison           1.0\n",
       "tajacu          1.0\n",
       "aberti          1.0\n",
       "Name: JaccardSimilarity, Length: 203, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most moving species = lowest average Jaccard\n",
    "# Insights You Can Drive\n",
    "#     Low Jaccard scores for a species over time → Highly moving species\n",
    "#     High Jaccard scores → Stationary or consistent habitat species\n",
    "df_species_movement.groupby('Species')['JaccardSimilarity'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3969267-5181-4d02-9b6d-ffe64590b850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster_Agglo_Updated\n",
       "189    0.740712\n",
       "169    0.725519\n",
       "24     0.702610\n",
       "176    0.700739\n",
       "96     0.695887\n",
       "196    0.692814\n",
       "111    0.674466\n",
       "131    0.669160\n",
       "5      0.663140\n",
       "170    0.660610\n",
       "8      0.655534\n",
       "19     0.654762\n",
       "116    0.651382\n",
       "157    0.650752\n",
       "1      0.648046\n",
       "37     0.639877\n",
       "156    0.624632\n",
       "75     0.618475\n",
       "130    0.615630\n",
       "42     0.610417\n",
       "88     0.609525\n",
       "151    0.608981\n",
       "64     0.602892\n",
       "147    0.602493\n",
       "0      0.602273\n",
       "21     0.586023\n",
       "164    0.578303\n",
       "56     0.576747\n",
       "141    0.568865\n",
       "54     0.566907\n",
       "183    0.554774\n",
       "125    0.552778\n",
       "99     0.545122\n",
       "10     0.542888\n",
       "71     0.538356\n",
       "79     0.525123\n",
       "61     0.517757\n",
       "4      0.506886\n",
       "29     0.490575\n",
       "91     0.484936\n",
       "53     0.449924\n",
       "51     0.444748\n",
       "74     0.393304\n",
       "Name: JaccardSimilarity, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most stable locations = highest average Jaccard\n",
    "# Same logic applies for locations:\n",
    "#     Low scores = site has high species turnover\n",
    "#     High scores = stable ecosystem\n",
    "df_cluster_movement.groupby('Cluster_Agglo_Updated')['JaccardSimilarity'].mean().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
